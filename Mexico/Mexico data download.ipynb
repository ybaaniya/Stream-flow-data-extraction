{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Function to download the CSV file\n",
    "def download_csv(url, folder):\n",
    "    # Get the file name from the URL\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    # Full path to save the file\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    # Download the CSV\n",
    "    response = requests.get(url)\n",
    "    with open(filepath, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Downloaded: {filename}\")\n",
    "\n",
    "# Function to scrape the webpage and find .csv links\n",
    "def download_csv_links_from_page(webpage_url, download_folder):\n",
    "    # Ensure the download folder exists\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    # Get the content of the webpage\n",
    "    response = requests.get(webpage_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all <a> tags with href that end in .csv\n",
    "    csv_links = [urljoin(webpage_url, a['href']) for a in soup.find_all('a', href=True) if a['href'].endswith('.csv')]\n",
    "\n",
    "    # Download each CSV link found\n",
    "    for link in csv_links:\n",
    "        download_csv(link, download_folder)\n",
    "\n",
    "\n",
    "webpage_url = 'https://sih.conagua.gob.mx/climas.html'\n",
    "download_folder = 'Path/to/save/the/csv/files'\n",
    "\n",
    "download_csv_links_from_page(webpage_url, download_folder)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
